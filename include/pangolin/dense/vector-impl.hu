#pragma once

#include <new>
#include <cstring>
#include <cassert>
#include <iostream>

#include "vector.hu"

#include "pangolin/utilities.hpp"
#include "pangolin/logger.hpp"

namespace pangolin
{

// default constructor
template <typename VALUE_TYPE>
__host__ Vector<VALUE_TYPE>::Vector() : capacity_(0), size_(0), data_(nullptr)
{
}

// move constructor
template <typename VALUE_TYPE>
__host__ Vector<VALUE_TYPE>::Vector(Vector &&other) : capacity_(other.capacity_), size_(other.size_), data_(other.data_)
{
    TRACE("move ctor");
    other.capacity_ = 0;
    other.size_ = 0;
    other.data_ = nullptr;
}

// copy constructor
template <typename VALUE_TYPE>
__host__ Vector<VALUE_TYPE>::Vector(const Vector &other) : Vector() {
    TRACE("copy ctor");
    reserve(other.capacity_);
    std::memcpy(data_, other.data_, other.size_ * sizeof(value_type));
    size_ = other.size_;
}

// destructor
template <typename VALUE_TYPE>
__host__ Vector<VALUE_TYPE>::~Vector()
{
    TRACE("dtor");
    if (data_)
    {
        for (size_t i = 0; i < size_; ++i)
        {
            (&data_[i])->~value_type();
        }

        CUDA_RUNTIME(cudaFree(data_));
        data_ = nullptr;
        capacity_ = 0;
        size_ = 0;
    }
}

// move-assignment
template <typename VALUE_TYPE>
__host__ Vector<VALUE_TYPE> &Vector<VALUE_TYPE>::operator=(Vector &&other) {
    TRACE("move assignment");

    // take ownership of other vector
    capacity_ = other.capacity_;
    size_ = other.size_;
    data_ = other.data_;

    // clear other after taking ownership of data
    other.capacity_ = 0;
    other.size_ = 0;
    other.data_ = nullptr;

    return *this;
}

template <typename VALUE_TYPE>
__host__ Vector<VALUE_TYPE>::Vector(size_t n)
{
    reserve(n);
    for (size_t i = 0; i < size_; ++i)
    {
        new (&data_[i]) value_type;
    }
}

template <typename VALUE_TYPE>
__host__ __device__ inline typename Vector<VALUE_TYPE>::value_type *Vector<VALUE_TYPE>::data() noexcept
{
    return data_;
}

template <typename VALUE_TYPE>
__host__ __device__ inline const typename Vector<VALUE_TYPE>::value_type *Vector<VALUE_TYPE>::data() const noexcept
{
    return data_;
}

template <typename VALUE_TYPE>
__host__ void Vector<VALUE_TYPE>::push_back(const Vector<VALUE_TYPE>::value_type &val)
{
    if (0 == size_)
    {
        reserve(1);
    }
    else if (size_ == capacity_)
    {
        TRACE("resize from {} -> {}", capacity_, capacity_ * 2);
        reserve(capacity_ * 2);
    }
    data_[size_] = val;
    ++size_;
}

template <typename VALUE_TYPE>
__host__ void Vector<VALUE_TYPE>::reserve(size_t n)
{
    if (n > capacity_)
    {
        value_type *newData = nullptr;
        CUDA_RUNTIME(cudaMallocManaged(&newData, sizeof(value_type) * n));
        std::memmove(newData, data_, sizeof(value_type) * size_);
        CUDA_RUNTIME(cudaFree(data_));
        data_ = newData;
        capacity_ = n;
    }
}

template <typename VALUE_TYPE>
__host__ void Vector<VALUE_TYPE>::resize(size_t n)
{
    if (n < size_)
    {
        // destroy elements beyond n
        for (size_t i = n; i < size_; ++i)
        {
            (&data_[i])->~value_type(); // manually call dtor
        }
    } else if (n > size_) {
        size_t initialSize = size_;
        reserve(n);
        for (size_t i = initialSize; i < n; ++i)
        {
            new (&data_[i]) value_type(); // new elements are value-initialized
        }
    }
}

template <typename VALUE_TYPE>
__host__ void Vector<VALUE_TYPE>::resize(size_t n, const value_type& val)
{
    if (n < size_)
    {
        // destroy elements beyond n
        for (size_t i = n; i < size_; ++i)
        {
            (&data_[i])->~value_type(); // manually call dtor
        }
    } else if (n > size_) {
        size_t initialSize = size_;
        reserve(n);
        for (size_t i = initialSize; i < n; ++i)
        {
            data_[i] = val;
        }
    }
}

template <typename VALUE_TYPE>
__host__ void Vector<VALUE_TYPE>::shrink_to_fit()
{
    assert(capacity_ >= size_);
    if (capacity_ > size_) {
        value_type *newData = nullptr;
        CUDA_RUNTIME(cudaMallocManaged(&newData, sizeof(value_type) * size_));
        std::memmove(newData, data_, sizeof(value_type) * size_);
        CUDA_RUNTIME(cudaFree(data_));
        data_ = newData;
        capacity_ = size_;
    }
}

template <typename VALUE_TYPE>
__host__ __device__ inline size_t Vector<VALUE_TYPE>::capacity() const noexcept
{
    return capacity_;
}

template <typename VALUE_TYPE>
__host__ __device__ inline size_t Vector<VALUE_TYPE>::size() const noexcept
{
    return size_;
}

template <typename VALUE_TYPE>
__host__ __device__ inline bool Vector<VALUE_TYPE>::empty() const noexcept
{
    return 0 == size_;
}

template <typename VALUE_TYPE>
__host__ __device__ inline typename Vector<VALUE_TYPE>::reference Vector<VALUE_TYPE>::operator[](size_t n)
{
    return data_[n];
}

template <typename VALUE_TYPE>
__host__ __device__ inline typename Vector<VALUE_TYPE>::const_reference Vector<VALUE_TYPE>::operator[](size_t n) const
{
    return data_[n];
}


} // namespace pangolin