#pragma once

#include <cassert>
#include <cstring>
#include <iostream>
#include <new>

#include "vector.hu"

#include "pangolin/logger.hpp"
#include "pangolin/utilities.hpp"

#ifdef __CUDACC__
#define PANGOLIN_HOST_DEVICE __host__ __device__
#define PANGOLIN_HOST __host__
#else
#define PANGOLIN_HOST_DEVICE
#define PANGOLIN_HOST
#endif

namespace pangolin {

template <typename VALUE_TYPE>
PANGOLIN_HOST Vector<VALUE_TYPE>::Vector(void) : capacity_(0), size_(0), data_(nullptr) {}

template <typename VALUE_TYPE>
PANGOLIN_HOST Vector<VALUE_TYPE>::Vector(size_t n) : capacity_(0), size_(0), data_(nullptr) {
  resize(n);
  for (size_t i = 0; i < size_; ++i) {
    new (&data_[i]) value_type;
  }
}

template <typename VALUE_TYPE>
PANGOLIN_HOST Vector<VALUE_TYPE>::Vector(size_t count, const_reference value) : capacity_(0), size_(0), data_(nullptr) {
  resize(count);
  for (size_t i = 0; i < size(); ++i) {
    data_[i] = value;
  }
}

/*!  initializer list
 */
template <typename VALUE_TYPE>
PANGOLIN_HOST Vector<VALUE_TYPE>::Vector(std::initializer_list<VALUE_TYPE> il)
    : capacity_(0), size_(0), data_(nullptr) {
  resize(il.size());
  auto it = il.begin();
  for (size_t i = 0; i < il.size(); ++i) {
    data_[i] = *it++;
  }
}

// move constructor
template <typename VALUE_TYPE>
PANGOLIN_HOST Vector<VALUE_TYPE>::Vector(Vector &&other)
    : capacity_(other.capacity_), size_(other.size_), data_(other.data_) {
  SPDLOG_TRACE(logger::console, "move ctor");
  other.capacity_ = 0;
  other.size_ = 0;
  other.data_ = nullptr;
}

// copy constructor
template <typename VALUE_TYPE>
PANGOLIN_HOST Vector<VALUE_TYPE>::Vector(const Vector &other) : capacity_(0), size_(0), data_(nullptr) {
  SPDLOG_TRACE(logger::console, "copy ctor");
  reserve(other.capacity_);
  std::memcpy(data_, other.data_, other.size_ * sizeof(value_type));
  size_ = other.size_;
}

// destructor
template <typename VALUE_TYPE> PANGOLIN_HOST Vector<VALUE_TYPE>::~Vector() {
  SPDLOG_TRACE(logger::console, "dtor");
  if (data_) {
    for (size_t i = 0; i < size_; ++i) {
      (&data_[i])->~value_type();
    }

    CUDA_RUNTIME(cudaFree(data_));
    data_ = nullptr;
    capacity_ = 0;
    size_ = 0;
  }
}

// move-assignment
template <typename VALUE_TYPE> PANGOLIN_HOST Vector<VALUE_TYPE> &Vector<VALUE_TYPE>::operator=(Vector &&other) {
  SPDLOG_TRACE(logger::console, "move assignment");

  capacity_ = other.capacity_;
  size_ = other.size_;
  
  // take ownership of other vector
  data_ = other.data_;

  // clear other after taking ownership of data
  other.capacity_ = 0;
  other.size_ = 0;
  other.data_ = nullptr;

  return *this;
}

// copy-assignment
template <typename VALUE_TYPE> PANGOLIN_HOST Vector<VALUE_TYPE> &Vector<VALUE_TYPE>::operator=(Vector &other) {
  SPDLOG_TRACE(logger::console, "copy assignment");
  capacity_ = other.capacity_;
  size_ = other.size_;
  std::memcpy(data_, other.data_, size_);

  return *this;
}

template <typename VALUE_TYPE>
PANGOLIN_HOST_DEVICE inline typename Vector<VALUE_TYPE>::value_type *Vector<VALUE_TYPE>::data() noexcept {
  return data_;
}

template <typename VALUE_TYPE>
PANGOLIN_HOST_DEVICE inline const typename Vector<VALUE_TYPE>::value_type *Vector<VALUE_TYPE>::data() const noexcept {
  return data_;
}

template <typename VALUE_TYPE>
PANGOLIN_HOST void Vector<VALUE_TYPE>::push_back(const Vector<VALUE_TYPE>::value_type &val) {
  if (0 == size_) {
    reserve(1);
  } else if (size_ == capacity_) {
    SPDLOG_TRACE(logger::console, "resize from {} -> {}", capacity_, capacity_ * 2);
    reserve(capacity_ * 2);
  }
  data_[size_] = val;
  ++size_;
}

template <typename VALUE_TYPE> PANGOLIN_HOST void Vector<VALUE_TYPE>::reserve(size_t n) {
  if (n > capacity_) {
    value_type *newData = nullptr;
    CUDA_RUNTIME(cudaMallocManaged(&newData, sizeof(value_type) * n));
    std::memmove(newData, data_, sizeof(value_type) * size_);
    CUDA_RUNTIME(cudaFree(data_));
    data_ = newData;
    capacity_ = n;
  }
}

template <typename VALUE_TYPE> PANGOLIN_HOST void Vector<VALUE_TYPE>::resize(size_t n) {
  if (n < size_) {
    // destroy elements beyond n
    for (size_t i = n; i < size_; ++i) {
      (&data_[i])->~value_type(); // manually call dtor
    }
  } else if (n > size_) {
    size_t initialSize = size_;
    reserve(n);
    size_ = n;
    for (size_t i = initialSize; i < n; ++i) {
      new (&data_[i]) value_type(); // new elements are value-initialized
    }
  }
}

template <typename VALUE_TYPE> PANGOLIN_HOST void Vector<VALUE_TYPE>::resize(size_t n, const value_type &val) {
  if (n < size_) {
    // destroy elements beyond n
    for (size_t i = n; i < size_; ++i) {
      (&data_[i])->~value_type(); // manually call dtor
    }
  } else if (n > size_) {
    size_t initialSize = size_;
    reserve(n);
    for (size_t i = initialSize; i < n; ++i) {
      data_[i] = val;
    }
  }
}

template <typename VALUE_TYPE> PANGOLIN_HOST void Vector<VALUE_TYPE>::shrink_to_fit() {
  assert(capacity_ >= size_);
  if (capacity_ > size_) {
    value_type *newData = nullptr;
    CUDA_RUNTIME(cudaMallocManaged(&newData, sizeof(value_type) * size_));
    std::memmove(newData, data_, sizeof(value_type) * size_);
    CUDA_RUNTIME(cudaFree(data_));
    data_ = newData;
    capacity_ = size_;
  }
}

template <typename T> PANGOLIN_HOST void Vector<T>::read_mostly() {
  // https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge37112fc1ac88d0f6bab7a945e48760a
  SPDLOG_TRACE(logger::console, "cudaMemAdviseSetReadMostly {}B on device", size() * sizeof(T));
  CUDA_RUNTIME(cudaMemAdvise(data_, size() * sizeof(T), cudaMemAdviseSetReadMostly, 0 /* ignored */));
}

template <typename T> PANGOLIN_HOST void Vector<T>::accessed_by(const int dev) {
  // https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge37112fc1ac88d0f6bab7a945e48760a
  CUDA_RUNTIME(cudaMemAdvise(data_, size() * sizeof(T), cudaMemAdviseSetAccessedBy, dev));
}

template <typename T> PANGOLIN_HOST void Vector<T>::prefetch_async(const int dev, cudaStream_t stream) {
  // https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42
  SPDLOG_TRACE(logger::console, "cudaMemPrefetchAsync {}B to device {} stream {}", size() * sizeof(T), dev,
               uintptr_t(stream));
  CUDA_RUNTIME(cudaMemPrefetchAsync(data_, size() * sizeof(T), dev, stream));
}

template <typename VALUE_TYPE> PANGOLIN_HOST_DEVICE inline size_t Vector<VALUE_TYPE>::capacity() const noexcept {
  return capacity_;
}

template <typename VALUE_TYPE> PANGOLIN_HOST_DEVICE inline size_t Vector<VALUE_TYPE>::size() const noexcept {
  return size_;
}

template <typename VALUE_TYPE> PANGOLIN_HOST_DEVICE inline bool Vector<VALUE_TYPE>::empty() const noexcept {
  return 0 == size_;
}

template <typename VALUE_TYPE>
PANGOLIN_HOST_DEVICE inline typename Vector<VALUE_TYPE>::reference Vector<VALUE_TYPE>::operator[](size_t n) {
  return data_[n];
}

template <typename VALUE_TYPE>
PANGOLIN_HOST_DEVICE inline
    typename Vector<VALUE_TYPE>::const_reference Vector<VALUE_TYPE>::operator[](size_t n) const {
  return data_[n];
}

} // namespace pangolin

#undef PANGOLIN_HOST_DEVICE
#undef PANGOLIN_HOST